{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\konst\\AppData\\Roaming\\Python\\Python36\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import uproot\n",
    "import pandas\n",
    "from functools import partial\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Dense, Conv2D, Dropout, AlphaDropout, Activation, BatchNormalization, Flatten\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "sys.path.insert(0, \"../../python\")\n",
    "from common import *\n",
    "from DataLoader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(prev_layer, filters, kernel_size, dropout_rate, block_name, n):\n",
    "    conv = Conv2D(filters, kernel_size, name=\"{}_conv_{}\".format(block_name, n),\n",
    "                  kernel_initializer='lecun_normal', activation='selu')(prev_layer)\n",
    "    if dropout_rate > 0:\n",
    "        return AlphaDropout(dropout_rate, name=\"{}_dropout_{}\".format(block_name, n))(conv)\n",
    "    return conv\n",
    "\n",
    "\n",
    "def reduce_n_features_2d(input_layer, first_layer_size, last_layer_size, decay_factor, block_name, dropout_rate):\n",
    "    conv_kernel=(1, 1)\n",
    "    prev_layer = input_layer\n",
    "    current_size = first_layer_size\n",
    "    n = 1\n",
    "    while True:\n",
    "        prev_layer = conv_block(prev_layer, current_size, conv_kernel, dropout_rate, block_name, n)\n",
    "        if current_size == last_layer_size: break\n",
    "        current_size = max(last_layer_size, int(current_size / decay_factor))\n",
    "        n += 1\n",
    "    return prev_layer\n",
    "\n",
    "def create_model():\n",
    "    dense_dropout_rate = 0.25\n",
    "    conv_dropout_rate = 0.25\n",
    "    first_layer_size = 256\n",
    "    last_layer_size = 16\n",
    "    decay_factor = 2\n",
    "    conv_decay_factor = 2\n",
    "        \n",
    "    model_name = \"DeepTau2017v2p2\"\n",
    "    input_layer_tau = Input(name=\"input_tau\", shape=(len(input_tau_branches),))\n",
    "    input_layers = [ input_layer_tau ]\n",
    "    \n",
    "    high_level_features = [ input_layer_tau ]\n",
    "    for loc in cell_locations:\n",
    "        reduced_inputs = []\n",
    "        for comp_id in range(len(component_names)):\n",
    "            comp_name = component_names[comp_id]\n",
    "            comp_branches = component_branches[comp_id]\n",
    "            input_layer_comp = Input(name=\"input_{}_{}\".format(loc, comp_name),\n",
    "                                     shape=(n_cells_eta[loc], n_cells_phi[loc], len(comp_branches)))\n",
    "            input_layers.append(input_layer_comp)\n",
    "            reduced_comp = reduce_n_features_2d(input_layer_comp, 128, 16, conv_decay_factor, \"{}_{}\".format(loc, comp_name),\n",
    "                                                conv_dropout_rate)\n",
    "            reduced_inputs.append(reduced_comp)\n",
    "        conv_all_start = Concatenate(name=\"{}_cell_concat\".format(loc), axis=3)(reduced_inputs)\n",
    "        cell_output_size = 32\n",
    "        prev_layer = conv_block(conv_all_start, cell_output_size, (1, 1), conv_dropout_rate,\n",
    "                                \"{}_all\".format(loc), 1)\n",
    "        window_size = 4\n",
    "        current_size = n_cells_eta[loc]\n",
    "        n = 1\n",
    "        while current_size > 1:\n",
    "            win_size = min(current_size, window_size)\n",
    "            prev_layer = conv_block(prev_layer, cell_output_size, (win_size, win_size), conv_dropout_rate,\n",
    "                                    \"{}_all_{}x{}\".format(loc, win_size, win_size), n)\n",
    "            n += 1\n",
    "            current_size -= window_size - 1\n",
    "            \n",
    "        cells_flatten = Flatten(name=\"{}_cells_flatten\".format(loc))(prev_layer)\n",
    "        high_level_features.append(cells_flatten)\n",
    "        \n",
    "    prev_layer = Concatenate(name=\"features_concat\")(high_level_features)\n",
    "    current_size = first_layer_size\n",
    "    n = 1\n",
    "    while True:\n",
    "        dense_layer = Dense(current_size, name=\"dense_%d\" % n, kernel_initializer='lecun_normal', activation='selu')(prev_layer)\n",
    "        if dense_dropout_rate > 0:\n",
    "            prev_layer = AlphaDropout(dense_dropout_rate, name=\"dropout_%d\" % n)(dense_layer)\n",
    "        else:\n",
    "            prev_layer = dense_layer\n",
    "        n += 1\n",
    "        if current_size == last_layer_size: break\n",
    "        current_size = max(last_layer_size, int(current_size / decay_factor))\n",
    "\n",
    "    output_layer = Dense(n_outputs, name=\"dense_%d\" % n)(prev_layer)\n",
    "    softmax_output = Activation(\"softmax\", name=\"main_output\")(output_layer)\n",
    "\n",
    "    model = Model(input_layers, softmax_output, name=\"DeepTau2017v2\")\n",
    "    return model, model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model, learning_rate):\n",
    "    #opt = keras.optimizers.Adam(lr=learning_rate)\n",
    "    opt = keras.optimizers.Nadam(lr=learning_rate)\n",
    "    #opt = keras.optimizers.SGD(lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "    #model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "    metrics = [\"accuracy\", TauLosses.Le, TauLosses.Lmu, TauLosses.Ljet, TauLosses.sLe, TauLosses.sLmu, TauLosses.sLjet ]\n",
    "    model.compile(loss=TauLosses.tau_crossentropy, optimizer=opt, metrics=metrics, weighted_metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_inner_pfCand (InputLayer) (None, 21, 21, 36)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_inner_ele (InputLayer)    (None, 21, 21, 39)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_inner_muon (InputLayer)   (None, 21, 21, 39)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inner_pfCand_conv_1 (Conv2D)    (None, 21, 21, 128)  4736        input_inner_pfCand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inner_ele_conv_1 (Conv2D)       (None, 21, 21, 128)  5120        input_inner_ele[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_conv_1 (Conv2D)      (None, 21, 21, 128)  5120        input_inner_muon[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_pfCand_dropout_1 (AlphaDr (None, 21, 21, 128)  0           inner_pfCand_conv_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_ele_dropout_1 (AlphaDropo (None, 21, 21, 128)  0           inner_ele_conv_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_dropout_1 (AlphaDrop (None, 21, 21, 128)  0           inner_muon_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inner_pfCand_conv_2 (Conv2D)    (None, 21, 21, 64)   8256        inner_pfCand_dropout_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inner_ele_conv_2 (Conv2D)       (None, 21, 21, 64)   8256        inner_ele_dropout_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_conv_2 (Conv2D)      (None, 21, 21, 64)   8256        inner_muon_dropout_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_pfCand_dropout_2 (AlphaDr (None, 21, 21, 64)   0           inner_pfCand_conv_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_ele_dropout_2 (AlphaDropo (None, 21, 21, 64)   0           inner_ele_conv_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_dropout_2 (AlphaDrop (None, 21, 21, 64)   0           inner_muon_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inner_pfCand_conv_3 (Conv2D)    (None, 21, 21, 32)   2080        inner_pfCand_dropout_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inner_ele_conv_3 (Conv2D)       (None, 21, 21, 32)   2080        inner_ele_dropout_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_conv_3 (Conv2D)      (None, 21, 21, 32)   2080        inner_muon_dropout_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_pfCand_dropout_3 (AlphaDr (None, 21, 21, 32)   0           inner_pfCand_conv_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_ele_dropout_3 (AlphaDropo (None, 21, 21, 32)   0           inner_ele_conv_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_dropout_3 (AlphaDrop (None, 21, 21, 32)   0           inner_muon_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "input_outer_pfCand (InputLayer) (None, 13, 13, 36)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_outer_ele (InputLayer)    (None, 13, 13, 39)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_outer_muon (InputLayer)   (None, 13, 13, 39)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inner_pfCand_conv_4 (Conv2D)    (None, 21, 21, 16)   528         inner_pfCand_dropout_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inner_ele_conv_4 (Conv2D)       (None, 21, 21, 16)   528         inner_ele_dropout_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_conv_4 (Conv2D)      (None, 21, 21, 16)   528         inner_muon_dropout_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_pfCand_conv_1 (Conv2D)    (None, 13, 13, 128)  4736        input_outer_pfCand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "outer_ele_conv_1 (Conv2D)       (None, 13, 13, 128)  5120        input_outer_ele[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_conv_1 (Conv2D)      (None, 13, 13, 128)  5120        input_outer_muon[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_pfCand_dropout_4 (AlphaDr (None, 21, 21, 16)   0           inner_pfCand_conv_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_ele_dropout_4 (AlphaDropo (None, 21, 21, 16)   0           inner_ele_conv_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_dropout_4 (AlphaDrop (None, 21, 21, 16)   0           inner_muon_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "outer_pfCand_dropout_1 (AlphaDr (None, 13, 13, 128)  0           outer_pfCand_conv_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_ele_dropout_1 (AlphaDropo (None, 13, 13, 128)  0           outer_ele_conv_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_dropout_1 (AlphaDrop (None, 13, 13, 128)  0           outer_muon_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inner_cell_concat (Concatenate) (None, 21, 21, 48)   0           inner_pfCand_dropout_4[0][0]     \n",
      "                                                                 inner_ele_dropout_4[0][0]        \n",
      "                                                                 inner_muon_dropout_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_pfCand_conv_2 (Conv2D)    (None, 13, 13, 64)   8256        outer_pfCand_dropout_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "outer_ele_conv_2 (Conv2D)       (None, 13, 13, 64)   8256        outer_ele_dropout_1[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "outer_muon_conv_2 (Conv2D)      (None, 13, 13, 64)   8256        outer_muon_dropout_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_conv_1 (Conv2D)       (None, 21, 21, 32)   1568        inner_cell_concat[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "outer_pfCand_dropout_2 (AlphaDr (None, 13, 13, 64)   0           outer_pfCand_conv_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_ele_dropout_2 (AlphaDropo (None, 13, 13, 64)   0           outer_ele_conv_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_dropout_2 (AlphaDrop (None, 13, 13, 64)   0           outer_muon_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_dropout_1 (AlphaDropo (None, 21, 21, 32)   0           inner_all_conv_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outer_pfCand_conv_3 (Conv2D)    (None, 13, 13, 32)   2080        outer_pfCand_dropout_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "outer_ele_conv_3 (Conv2D)       (None, 13, 13, 32)   2080        outer_ele_dropout_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_conv_3 (Conv2D)      (None, 13, 13, 32)   2080        outer_muon_dropout_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_4x4_conv_1 (Conv2D)   (None, 18, 18, 32)   16416       inner_all_dropout_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_pfCand_dropout_3 (AlphaDr (None, 13, 13, 32)   0           outer_pfCand_conv_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_ele_dropout_3 (AlphaDropo (None, 13, 13, 32)   0           outer_ele_conv_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_dropout_3 (AlphaDrop (None, 13, 13, 32)   0           outer_muon_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_4x4_dropout_1 (AlphaD (None, 18, 18, 32)   0           inner_all_4x4_conv_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_pfCand_conv_4 (Conv2D)    (None, 13, 13, 16)   528         outer_pfCand_dropout_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "outer_ele_conv_4 (Conv2D)       (None, 13, 13, 16)   528         outer_ele_dropout_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_conv_4 (Conv2D)      (None, 13, 13, 16)   528         outer_muon_dropout_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_4x4_conv_2 (Conv2D)   (None, 15, 15, 32)   16416       inner_all_4x4_dropout_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_pfCand_dropout_4 (AlphaDr (None, 13, 13, 16)   0           outer_pfCand_conv_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_ele_dropout_4 (AlphaDropo (None, 13, 13, 16)   0           outer_ele_conv_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_dropout_4 (AlphaDrop (None, 13, 13, 16)   0           outer_muon_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_4x4_dropout_2 (AlphaD (None, 15, 15, 32)   0           inner_all_4x4_conv_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_cell_concat (Concatenate) (None, 13, 13, 48)   0           outer_pfCand_dropout_4[0][0]     \n",
      "                                                                 outer_ele_dropout_4[0][0]        \n",
      "                                                                 outer_muon_dropout_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_4x4_conv_3 (Conv2D)   (None, 12, 12, 32)   16416       inner_all_4x4_dropout_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_conv_1 (Conv2D)       (None, 13, 13, 32)   1568        outer_cell_concat[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_4x4_dropout_3 (AlphaD (None, 12, 12, 32)   0           inner_all_4x4_conv_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_dropout_1 (AlphaDropo (None, 13, 13, 32)   0           outer_all_conv_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_4x4_conv_4 (Conv2D)   (None, 9, 9, 32)     16416       inner_all_4x4_dropout_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_4x4_conv_1 (Conv2D)   (None, 10, 10, 32)   16416       outer_all_dropout_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_4x4_dropout_4 (AlphaD (None, 9, 9, 32)     0           inner_all_4x4_conv_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_4x4_dropout_1 (AlphaD (None, 10, 10, 32)   0           outer_all_4x4_conv_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_4x4_conv_5 (Conv2D)   (None, 6, 6, 32)     16416       inner_all_4x4_dropout_4[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_4x4_conv_2 (Conv2D)   (None, 7, 7, 32)     16416       outer_all_4x4_dropout_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_4x4_dropout_5 (AlphaD (None, 6, 6, 32)     0           inner_all_4x4_conv_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_4x4_dropout_2 (AlphaD (None, 7, 7, 32)     0           outer_all_4x4_conv_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_4x4_conv_6 (Conv2D)   (None, 3, 3, 32)     16416       inner_all_4x4_dropout_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_4x4_conv_3 (Conv2D)   (None, 4, 4, 32)     16416       outer_all_4x4_dropout_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_4x4_dropout_6 (AlphaD (None, 3, 3, 32)     0           inner_all_4x4_conv_6[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_4x4_dropout_3 (AlphaD (None, 4, 4, 32)     0           outer_all_4x4_conv_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_conv_7 (Conv2D)   (None, 1, 1, 32)     9248        inner_all_4x4_dropout_6[0][0]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "outer_all_4x4_conv_4 (Conv2D)   (None, 1, 1, 32)     16416       outer_all_4x4_dropout_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_dropout_7 (AlphaD (None, 1, 1, 32)     0           inner_all_3x3_conv_7[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_4x4_dropout_4 (AlphaD (None, 1, 1, 32)     0           outer_all_4x4_conv_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "input_tau (InputLayer)          (None, 44)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inner_cells_flatten (Flatten)   (None, 32)           0           inner_all_3x3_dropout_7[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_cells_flatten (Flatten)   (None, 32)           0           outer_all_4x4_dropout_4[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "features_concat (Concatenate)   (None, 108)          0           input_tau[0][0]                  \n",
      "                                                                 inner_cells_flatten[0][0]        \n",
      "                                                                 outer_cells_flatten[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          27904       features_concat[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (AlphaDropout)        (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (AlphaDropout)        (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           8256        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (AlphaDropout)        (None, 64)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           2080        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (AlphaDropout)        (None, 32)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16)           528         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (AlphaDropout)        (None, 16)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 4)            68          dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Activation)        (None, 4)            0           dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 343,412\n",
      "Trainable params: 343,412\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "TauLosses.SetSFs(2, 1, 5)\n",
    "model, model_name = create_model()\n",
    "compile_model(model, 1e-3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_file(f_name):\n",
    "    file_objs = [ obj for obj in gc.get_objects() if (\"TextIOWrapper\" in str(type(obj))) and (obj.name == f_name)]\n",
    "    for obj in file_objs:\n",
    "        obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(train_suffix, model_name, data_loader, epoch, n_epochs):\n",
    "\n",
    "    train_name = '%s_%s' % (model_name, train_suffix)\n",
    "    \n",
    "    cb_acc = []\n",
    "    for acc_name in [\"acc\", \"weighted_acc\"]:\n",
    "        cb_acc.append(ModelCheckpoint(\"%s_acc.hdf5\" % train_name, monitor=\"val_%s\" % acc_name, save_best_only=True,\n",
    "                                      save_weights_only=False, mode=\"max\", verbose=1))\n",
    "    \n",
    "    cb_losses = []\n",
    "    for loss_name in [\"loss\", \"Le\", \"Lmu\", \"Ljet\", \"weighted_Le\", \"weighted_Lmu\", \"weighted_Ljet\"]:\n",
    "        cb_losses.append(ModelCheckpoint(\"%s_%s.hdf5\" % (train_name, loss_name), monitor=\"val_%s\" % loss_name,\n",
    "                                         save_best_only=True, save_weights_only=False, mode=\"min\", verbose=1))\n",
    "\n",
    "    log_name = \"%s.log\" % train_name\n",
    "    if os.path.isfile(log_name):\n",
    "        close_file(log_name)\n",
    "        os.remove(log_name)\n",
    "    csv_log = CSVLogger(log_name, append=True)\n",
    "\n",
    "    pbar = TQDMNotebookCallback(leave_outer=True, show_outer=True, leave_inner = True)\n",
    "    callbacks = [pbar, csv_log, *cb_acc, *cb_losses]\n",
    "    fit_hist = model.fit_generator(data_loader.generator(True), validation_data=data_loader.generator(False),\n",
    "                                   steps_per_epoch=data_loader.steps_per_epoch, validation_steps=data_loader.validation_steps,\n",
    "                                   callbacks=callbacks, epochs=n_epochs, initial_epoch=epoch, verbose=0)\n",
    "\n",
    "    model.save(\"%s_final.hdf5\" % train_name)\n",
    "    return fit_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72491602 65000000 7491602\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader('file://N:/tau-ml/tuples-v2-t2/training.root', 500, 1000, validation_size=7491602,\n",
    "                    max_queue_size=4, n_passes=-1)\n",
    "print(loader.file_size, loader.data_size, loader.validation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de93b86f5744fdb9523e2b9cdf2b5be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=4, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecbd9bddd05c4953b2d035e50db03a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=130000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit_hist = run_training('step1', model_name, loader, 0, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
